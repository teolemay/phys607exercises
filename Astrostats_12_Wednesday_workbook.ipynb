{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Astrostats Week 12: Other Methods\n",
    "Nonnegative matrix factorization and independent component analysis are two other dimensionality reduction approaches that can sometimes Paraphrase(be better than pca in certain cicumstances when you know a few prior facts about your data, e.g. non-negative, independent sources, correlations, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, FastICA, NMF \n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.measure import block_reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Compare \"important components\" found by NMF and PCA\n",
    "Due to different constraints on the results, NMF and PCA will return different solutions to a similar matrix factorization problem. Sometimes, NMF can return components with more interesting features patterns than PCA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, FastICA, NMF \n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.measure import block_reduce\n",
    "\n",
    "# Convenient plotting function\n",
    "def plot_gallery(title, images, n_col=3, n_row=3, cmap='viridis'):\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=n_row,\n",
    "        ncols=n_col,\n",
    "        figsize=(2.0 * n_col, 2.3 * n_row),\n",
    "        facecolor=\"white\",\n",
    "        constrained_layout=True,\n",
    "    )\n",
    "    fig.set_constrained_layout_pads(w_pad=0.01, h_pad=0.02, hspace=0, wspace=0)\n",
    "    fig.set_edgecolor(\"black\")\n",
    "    fig.suptitle(title, size=16)\n",
    "    for ax, vec in zip(axs.flat, images):\n",
    "        vmax = max(vec.max(), -vec.min())\n",
    "        im = ax.imshow(\n",
    "            vec.reshape(int(np.sqrt(vec.size)), int(np.sqrt(vec.size))),\n",
    "            cmap=cmap,\n",
    "            interpolation=\"nearest\",\n",
    "            vmin=np.min(images),\n",
    "            vmax=vmax,\n",
    "        )\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    fig.colorbar(im, ax=axs, orientation=\"horizontal\", shrink=0.99, aspect=40, pad=0.01)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get faces dataset\n",
    "faces, _ = fetch_olivetti_faces(return_X_y=True, shuffle=True, random_state=1)\n",
    "plot_gallery('faces', faces[:25], n_col=5, n_row=5, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling faces makes Component patterns easier to see\n",
    "sqfaces = np.reshape(faces, (len(faces), 64, 64))\n",
    "tmp = np.zeros((len(faces), 48, 48))\n",
    "data = np.zeros((len(faces), 16,16))\n",
    "for i in range(len(faces)):\n",
    "    tmp[i] = sqfaces[i, 8:-8, 8:-8]\n",
    "    data[i] = block_reduce(tmp[i], block_size=3, func=np.mean)\n",
    "\n",
    "data = np.reshape(data, (len(faces), 16*16))\n",
    "\n",
    "plot_gallery('downsampled_faces', data[:25], n_col=5, n_row=5, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use PCA to determine the best number of components to use in your NMF fit.\n",
    "<details>\n",
    "  <summary>Hint 1:</summary>\n",
    "    Try plotting the the variance and cumulative sum of PCA component variances. `pca.explained_variance_ratio_` gives the ratio of the variance explained by each PC.\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "  <summary>Hint 2:</summary>\n",
    "    If there aren't any obvious elbow points in the variance plots, you can choose an arbitrary percentage of explained variance (e.g. 90%).\n",
    "</details>\n",
    "\n",
    "2. Fit the downsampled faces dataset using NMF and PCA and comapre the important components by plotting them with `plot_gallery`. \n",
    "\n",
    "3. Try tuning the number of NMF components to fit. PCA calculates all the orthogonal principle components (limited by the SVD parameters), but NMF results can vary depending on the number of components set.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=200)\n",
    "pca.fit(data)\n",
    "cumulative_var = np.cumsum(pca.explained_variance_ratio_)\n",
    "print(np.argwhere(cumulative_var > 0.9)[0])\n",
    "plt.figure()\n",
    "plt.plot(cumulative_var, '.-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=25, max_iter=1000)\n",
    "nmf.fit(data)\n",
    "proj = nmf.transform(data)\n",
    "comp = nmf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gallery('NMF components', comp, n_col=5, n_row=5, cmap='viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pcacomp = pca.components_\n",
    "print(pcacomp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gallery('pca components', pcacomp, n_row=5, n_col=5, cmap='viridis')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try changing the downsampling (or completely removing it) on the Olivetti faces dataset. The NMF components might not pick out the same facial features as components!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = faces\n",
    "nmf = NMF(n_components=25, max_iter=1000)\n",
    "nmf.fit(data)\n",
    "proj = nmf.transform(data)\n",
    "comp = nmf.components_\n",
    "\n",
    "pca = PCA(n_components=200)\n",
    "pca.fit(data)\n",
    "pcacomp = pca.components_\n",
    "print(pcacomp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gallery('NMF components', comp, n_col=5, n_row=5, cmap='viridis')\n",
    "\n",
    "plot_gallery('pca components', pcacomp, n_row=5, n_col=5, cmap='viridis')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Unmixing linear combinations of waveforms with ICA\n",
    "Let's create some sample data from random combinations of a few different waveforms. Use ICA to get the source signals back out of the combined waveforms. How does changing the number of components of the ICA fit affect result? Compare the ICA results to PCA principle components. PCA often performs at least equally as well as ICA.\n",
    "<details>\n",
    "  <summary>Hint</summary>\n",
    "    The `FastICA` implementation from sklearn has the same syntax as `PCA` and `NMF`.\n",
    "</details>\n",
    "\n",
    "Repeat the data generation, and both fitting methods a few times. Does ICA perform better on average than PCA? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some source signals\n",
    "from scipy.signal import sawtooth\n",
    "\n",
    "\n",
    "t = np.linspace(0, 2*np.pi, 200)\n",
    "# You can change waveform parameters or add new source signals too!\n",
    "sine_wave = np.sin(t*15)\n",
    "saw_wave = -sawtooth(t*7)\n",
    "tan_wave = np.sin(np.tan(t*4)/20)\n",
    "noise = np.random.normal(0, 1, (200))\n",
    "\n",
    "# Make some linear combinations of signals\n",
    "combination = np.random.uniform(0, 1, (100, 4))\n",
    "functions_mat = np.stack([sine_wave, saw_wave, noise, tan_wave])\n",
    "functions_mat.shape\n",
    "data = (combination @ functions_mat) \n",
    "data = data - np.mean(data, axis=0) # data whitening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ica = FastICA(n_components=4, max_iter=1000)\n",
    "ica.fit(data)\n",
    "\n",
    "comp = ica.components_\n",
    "plt.subplots(4,1)\n",
    "for i in range(4):\n",
    "    plt.subplot(4, 1, i+1)\n",
    "    plt.plot(t, comp[i])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=100)\n",
    "pca.fit(data)\n",
    "comp = pca.components_\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(pca.explained_variance_ratio_[:10])\n",
    "plt.show()\n",
    "\n",
    "print(comp.shape)\n",
    "plt.subplots(5,1)\n",
    "for i in range(5):\n",
    "    plt.subplot(5,1,i+1)\n",
    "    plt.plot(t, comp[i])\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: unmixing mistery signals\n",
    "`mystery.txt` is a dataset containing 100 different combinations of a few characteristic signals. Use any method of your choice from Monday or Wednesday to find the underlying patterns in the data!\n",
    "\n",
    "<details>\n",
    "  <summary>Hint:</summary>\n",
    "    Try running components through IPython.display.Audio, as in `Audio(component, rate=9600)`\n",
    "</details>\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "dataset = np.load(r'mistery.npy')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50)\n",
    "pca.fit(dataset)\n",
    "pcacomp = pca.components_ \n",
    "\n",
    "plt.figure()\n",
    "plt.plot(pca.explained_variance_ratio_[:20])\n",
    "plt.show()\n",
    "\n",
    "print(pcacomp.shape)\n",
    "plt.subplots(7,1)\n",
    "for i in range(7):\n",
    "    plt.subplot(7,1,i+1)\n",
    "    plt.plot(pcacomp[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(pcacomp[5], rate=9600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n= 6\n",
    "ica = FastICA(n_components=n, max_iter=1000)\n",
    "ica.fit(dataset)\n",
    "\n",
    "icacomp = ica.components_#/np.max(ica.components_, axis=0)\n",
    "plt.subplots(n,1)\n",
    "for i in range(n):\n",
    "    plt.subplot(n, 1, i+1)\n",
    "    plt.plot(icacomp[i])\n",
    "    # plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(icacomp[0], rate=9600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coursework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Astrostats Week 12: Other Methods\n",
    "Nonnegative matrix factorization and independent component analysis are two other dimensionality reduction approaches that can sometimes do a better job at picking out interesting underlying patterns than PCA. Both of these methods rely on some fundamental assumptions about the domain and source of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Compare \"important components\" found by NMF and PCA\n",
    "Due to different constraints on the results, NMF and PCA will return different solutions to a similar matrix factorization problem. Sometimes, NMF can return components with more interesting features patterns than PCA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Read in and become familar with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, FastICA, NMF \n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.measure import block_reduce\n",
    "\n",
    "# Convenient plotting function\n",
    "def plot_gallery(title, images, n_col=3, n_row=3, cmap='viridis'):\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=n_row,\n",
    "        ncols=n_col,\n",
    "        figsize=(2.0 * n_col, 2.3 * n_row),\n",
    "        facecolor=\"white\",\n",
    "        constrained_layout=True,\n",
    "    )\n",
    "    fig.set_constrained_layout_pads(w_pad=0.01, h_pad=0.02, hspace=0, wspace=0)\n",
    "    fig.set_edgecolor(\"black\")\n",
    "    fig.suptitle(title, size=16)\n",
    "    for ax, vec in zip(axs.flat, images):\n",
    "        vmax = max(vec.max(), -vec.min())\n",
    "        im = ax.imshow(\n",
    "            vec.reshape(int(np.sqrt(vec.size)), int(np.sqrt(vec.size))),\n",
    "            cmap=cmap,\n",
    "            interpolation=\"nearest\",\n",
    "            vmin=np.min(images),\n",
    "            vmax=vmax,\n",
    "        )\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    fig.colorbar(im, ax=axs, orientation=\"horizontal\", shrink=0.99, aspect=40, pad=0.01)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get faces dataset\n",
    "faces, _ = fetch_olivetti_faces(return_X_y=True, shuffle=True, random_state=1)\n",
    "plot_gallery('faces', faces[:25], n_col=5, n_row=5, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Downsample the data**  \n",
    "Downsampling faces makes Component patterns easier to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocksize = 3\n",
    "\n",
    "sqfaces = np.reshape(faces, (len(faces), 64, 64))\n",
    "tmp = np.zeros((len(faces), 48, 48))\n",
    "data = np.zeros((len(faces), 16,16))\n",
    "for i in range(len(faces)):\n",
    "    tmp[i] = sqfaces[i, 8:-8, 8:-8]\n",
    "    data[i] = block_reduce(tmp[i], block_size=blocksize, func=np.mean)\n",
    "\n",
    "faces_data = np.reshape(data, (len(faces), 16*16))\n",
    "\n",
    "plot_gallery('downsampled_faces', data[:25], n_col=5, n_row=5, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Use PCA to determine the best number of components to use in your NMF fit.\n",
    "\n",
    "We've used the [sklearn PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)  function to perform PCA on the downsampled `faces_data`.  \n",
    "Determine the set of principal components which contain most of the information (the important components).\n",
    "\n",
    "<details>\n",
    "  <summary>Hint 1:</summary>\n",
    "    Try plotting the the variance and cumulative sum of PCA component variances.   \n",
    "    `pca.explained_variance_ratio_` gives the ratio of the variance explained by each PC.\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "  <summary>Hint 2:</summary>\n",
    "    If there aren't any obvious elbow points in the variance plots, you can choose an arbitrary percentage of explained variance (e.g. 90%).\n",
    "    Try finding the number of components at which the cumulative variance becomes greater than 90%\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- \n",
    "n_pca = 100 # Your code here! what is the maximum pca dimensionality?  Hint: its related to the number of samples and the number of features\n",
    "\n",
    "pca = PCA(n_components=n_pca )\n",
    "pca.fit(faces_data)\n",
    "pca_comps = pca.components_\n",
    "\n",
    "cumulative_var = np.cumsum(pca.explained_variance_ratio_)\n",
    "print('90% variance at:', np.argwhere(cumulative_var > 0.9)[0])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(cumulative_var, '.-', label='Cummulative explained variance')\n",
    "plt.plot(pca.explained_variance_ratio_, '.-', label='Explained variance per PC')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Fit the `faces_data` samples with NMF!\n",
    "\n",
    "Try the [sklearn NMF](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html#sklearn.decomposition.NMF)  function to perform NMF on the downsampled `faces_data`.   \n",
    "\n",
    "\n",
    "<details>\n",
    "  <summary>Hint</summary>\n",
    "   The syntax is very similar to the PCA syntax.\n",
    "</details>\n",
    "\n",
    "Compare the important components by plotting them with `plot_gallery`.  How do the important PCA components compare to the important NMF components?\n",
    "\n",
    "\n",
    "**Play Around**  \n",
    "Try tuning the number of NMF components to fit. PCA calculates all the orthogonal principle components (limited by the SVD parameters), but NMF results can vary depending on the number of components set.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nmf = 25 # your code here! Hint: use the number of components you found above\n",
    "\n",
    "nmf = NMF(n_components=n_nmf, max_iter=1000)\n",
    "nmf.fit(data)\n",
    "proj = nmf.transform(data)\n",
    "nmf_comps = nmf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gallery('NMF components', nmf_comps, n_col=5, n_row=5, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gallery('pca components', pca_comps, n_row=5, n_col=5, cmap='viridis')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Play Around**\n",
    "\n",
    "Try changing the downsampling (or completely removing it) on the Olivetti faces dataset. The NMF components might not pick out the same facial features as components!\n",
    "\n",
    "You can change the `blocksize` parameter above, or apply dimensionality reduction directly to the `faces` array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = faces\n",
    "nmf = NMF(n_components=25, max_iter=1000)\n",
    "nmf.fit(data)\n",
    "proj = nmf.transform(data)\n",
    "comp = nmf.components_\n",
    "\n",
    "pca = PCA(n_components=200)\n",
    "pca.fit(data)\n",
    "pcacomp = pca.components_\n",
    "print(pcacomp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gallery('NMF components', comp, n_col=5, n_row=5, cmap='viridis')\n",
    "\n",
    "plot_gallery('pca components', pcacomp, n_row=5, n_col=5, cmap='viridis')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "### Exercise 2: Unmixing linear combinations of waveforms with ICA\n",
    "\n",
    "Let's create some sample data from random combinations of a few different waveforms. \n",
    "\n",
    "Use ICA to get the source signals back out of the combined waveforms. \n",
    "How does changing the number of components of the ICA fit affect result? \n",
    "\n",
    "\n",
    "<details>\n",
    "  <summary>Hint</summary>\n",
    "\n",
    "  The `FastICA` implementation from sklearn has the same syntax as `PCA` and `NMF`.\n",
    "  \n",
    "</details>\n",
    "\n",
    "Repeat the data generation, and both fitting methods a few times. Does ICA perform better on average than PCA? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some source signals\n",
    "from scipy.signal import sawtooth\n",
    "\n",
    "\n",
    "t = np.linspace(0, 2*np.pi, 200)\n",
    "# You can change waveform parameters or add new source signals too!\n",
    "sine_wave = np.sin(t*15)\n",
    "saw_wave = -sawtooth(t*7)\n",
    "tan_wave = np.sin(np.tan(t*4)/20)\n",
    "noise = np.random.normal(0, 1, (200))\n",
    "\n",
    "# Make some linear combinations of signals\n",
    "combination = np.random.uniform(0, 1, (100, 4))\n",
    "functions_mat = np.stack([sine_wave, saw_wave, noise, tan_wave])\n",
    "functions_mat.shape\n",
    "data = (combination @ functions_mat) \n",
    "data = data - np.mean(data, axis=0) # data whitening\n",
    "\n",
    "plt.figure()\n",
    "plt.title('One of the mixed signals')\n",
    "plt.plot(t, data[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ica = 4# Your code here! how many components should you use? \n",
    "ica = FastICA(n_components=n_ica, max_iter=1000)\n",
    "ica.fit(data)\n",
    "\n",
    "comp = ica.components_\n",
    "plt.subplots(4,1)\n",
    "for i in range(4):\n",
    "    plt.subplot(4, 1, i+1)\n",
    "    plt.plot(t, comp[i])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pca = 100 # Your code here! how many components should you use? \n",
    "pca = PCA(n_components= n_pca) \n",
    "\n",
    "pca.fit(data)\n",
    "comp = pca.components_\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Cumulative explained variance')\n",
    "plt.plot(pca.explained_variance_ratio_[:10])\n",
    "plt.show()\n",
    "\n",
    "print(comp.shape)\n",
    "plt.subplots(5,1)\n",
    "for i in range(5):\n",
    "    plt.subplot(5,1,i+1)\n",
    "    plt.plot(t, comp[i])\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 3: unmixing mistery signals\n",
    "`mystery.txt` is a dataset containing 100 different combinations of a few characteristic signals. Use any method of your choice from Monday or Wednesday to find the underlying patterns in the data!\n",
    "\n",
    "This dataset has already been standardized.\n",
    "\n",
    "<details>\n",
    "  <summary>Hint:</summary>\n",
    "    Try running components through IPython.display.Audio, as in `Audio(component, rate=9600)`\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Load in and become familar with the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "dataset = np.load(r'mistery.npy')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind2Show = 0 # Try different signals in the dataset!\n",
    "\n",
    "plt.figure(figsize=(10,2))\n",
    "plt.title('Signal {}'.format(ind2Show))\n",
    "\n",
    "plt.plot(dataset[ind2Show],linewidth=0.5)\n",
    "Audio(dataset[ind2Show], rate=9600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Choose a dimension reduction method (PCA, NMF, or ICA), and find the most important components in the data\n",
    "Plot and play these components, what do you notice? How do they compare to the original signals?\n",
    "\n",
    "**Play Around**\n",
    "Try each method and compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50)\n",
    "pca.fit(dataset)\n",
    "pcacomp = pca.components_ \n",
    "\n",
    "plt.figure()\n",
    "plt.plot(pca.explained_variance_ratio_[:20])\n",
    "plt.show()\n",
    "\n",
    "print(pcacomp.shape)\n",
    "plt.subplots(7,1)\n",
    "for i in range(7):\n",
    "    plt.subplot(7,1,i+1)\n",
    "    plt.plot(pcacomp[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(pcacomp[5], rate=9600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n= 6\n",
    "ica = FastICA(n_components=n, max_iter=1000)\n",
    "ica.fit(dataset)\n",
    "\n",
    "icacomp = ica.components_#/np.max(ica.components_, axis=0)\n",
    "plt.subplots(n,1)\n",
    "for i in range(n):\n",
    "    plt.subplot(n, 1, i+1)\n",
    "    plt.plot(icacomp[i])\n",
    "    # plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(icacomp[0], rate=9600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coursework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
